import os
import time
import uuid
from dotenv import load_dotenv

from pinecone import Pinecone
from qdrant_client import QdrantClient
from qdrant_client.models import VectorParams, Distance, PointStruct
from qdrant_client.http.exceptions import UnexpectedResponse

# =========================
# è¨­å®š
# =========================
load_dotenv()

PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")
PINECONE_INDEX_NAME = "raiden-main"
PINECONE_NAMESPACE = ""  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ namespace

QDRANT_URL = os.getenv("QDRANT_URL", "http://localhost:6333")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY")
QDRANT_COLLECTION = "raiden-main"

VECTOR_DIM = 1536
QDRANT_DISTANCE = Distance.COSINE

# Qdrant ã«ä¸€åº¦ã«æŠ•ã’ã‚‹ãƒã‚¤ãƒ³ãƒˆæ•°
MAX_QDRANT_BATCH = 64
MAX_RETRIES = 5

# ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
DEBUG_MODE = False


def validate_env():
    missing = []
    if not PINECONE_API_KEY:
        missing.append("PINECONE_API_KEY")
    if missing:
        raise RuntimeError(f"ç’°å¢ƒå¤‰æ•°ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {', '.join(missing)}")

    print(f"QDRANT_URL = {QDRANT_URL}")
    print(f"QDRANT_API_KEY set? = {bool(QDRANT_API_KEY)}")


def init_pinecone():
    pc = Pinecone(api_key=PINECONE_API_KEY)

    index_host = os.getenv("PINECONE_INDEX_HOST")
    if index_host:
        index = pc.Index(host=index_host)
        print(f"Using Pinecone index host: {index_host}")
    else:
        index = pc.Index(PINECONE_INDEX_NAME)
        print(f"Using Pinecone index name: {PINECONE_INDEX_NAME}")
    return index


def init_qdrant():
    client = QdrantClient(
        url=QDRANT_URL,
        api_key=QDRANT_API_KEY,
        timeout=180  # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’180ç§’ã«è¨­å®š
    )
    
    # æ¥ç¶šãƒ†ã‚¹ãƒˆ
    try:
        collections = client.get_collections()
        print(f"âœ… Qdrantæ¥ç¶šæˆåŠŸã€‚ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(collections.collections)}")
    except Exception as e:
        print(f"âŒ Qdrantæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        raise

    # ã™ã§ã«ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚ã‚Œã°ã€Œãã®ã¾ã¾ä½¿ã†ã€
    if not client.collection_exists(QDRANT_COLLECTION):
        client.create_collection(
            collection_name=QDRANT_COLLECTION,
            vectors_config=VectorParams(
                size=VECTOR_DIM,
                distance=QDRANT_DISTANCE,
            ),
        )
        print(f"Qdrant collection '{QDRANT_COLLECTION}' ã‚’æ–°è¦ä½œæˆã—ã¾ã—ãŸ")
    else:
        info = client.get_collection(QDRANT_COLLECTION)
        count = getattr(info, "points_count", None)
        if count is None:
            count = getattr(info, "vectors_count", None)
        print(
            f"Qdrant collection '{QDRANT_COLLECTION}' ã¯æ—¢ã«å­˜åœ¨ã—ã¾ã™ "
            f"(ç¾åœ¨ã®ãƒ™ã‚¯ãƒˆãƒ«æ•°: {count if count is not None else 'unknown'})"
        )
        print("æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¯å‰Šé™¤ã›ãšã€ä¸Šæ›¸ãã—ãªãŒã‚‰è¿½åŠ ã—ã¾ã™ã€‚")

    return client


def to_uuid_from_pinecone_id(vid: str) -> str:
    """Pinecone ã® string ID ã‚’ Qdrant ç”¨ã® UUID ã«å¤‰æ›ï¼ˆæ±ºå®šçš„ï¼‰"""
    return str(uuid.uuid5(uuid.NAMESPACE_DNS, f"raiden-main:{vid}"))


def flatten_payload(metadata: dict, original_id: str) -> dict:
    """
    ãƒã‚¹ãƒˆæ§‹é€ ã®payloadã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã™ã‚‹
    
    Before:
    {
        "page_content": "...",
        "metadata": {
            "type": "content",
            "weight": 1.0,
            "title": "...",
            ...
        }
    }
    
    After:
    {
        "text": "...",
        "type": "content",
        "weight": 1.0,
        "title": "...",
        "original_id": "...",
        ...
    }
    """
    # ãƒ‡ãƒãƒƒã‚°: æœ€åˆã®æ•°ä»¶ã§æ§‹é€ ã‚’ç¢ºèª
    if not hasattr(flatten_payload, 'debug_count'):
        flatten_payload.debug_count = 0
    
    if flatten_payload.debug_count < 3:
        print(f"\n=== Payload æ§‹é€ ãƒ‡ãƒãƒƒã‚° {flatten_payload.debug_count + 1} ===")
        print(f"Keys: {list(metadata.keys())}")
        flatten_payload.debug_count += 1
    
    flattened = {}
    
    # ãƒã‚¹ãƒˆæ§‹é€ ã®å ´åˆ
    if "metadata" in metadata:
        # page_content ã‚’ text ã«å¤‰æ›
        if "page_content" in metadata:
            flattened["text"] = metadata["page_content"]
        
        # metadata ã®ä¸­èº«ã‚’å…¨ã¦å±•é–‹
        nested_metadata = metadata["metadata"]
        if isinstance(nested_metadata, dict):
            flattened.update(nested_metadata)
        
        # metadataä»¥å¤–ã®ãƒˆãƒƒãƒ—ãƒ¬ãƒ™ãƒ«ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚‚ä¿æŒ
        for key, value in metadata.items():
            if key not in ["metadata", "page_content"]:
                flattened[key] = value
    
    # æ—¢ã«ãƒ•ãƒ©ãƒƒãƒˆãªæ§‹é€ ã®å ´åˆ
    else:
        flattened = metadata.copy()
        
        # page_content ãŒå­˜åœ¨ã—ãŸã‚‰ text ã«å¤‰æ›
        if "page_content" in flattened:
            flattened["text"] = flattened.pop("page_content")
    
    # original_id ã‚’å¿…ãšè¿½åŠ 
    flattened["original_id"] = original_id
    
    return flattened


def safe_upsert(qdrant: QdrantClient, points_batch):
    """502ã‚„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆãŒå‡ºãŸã‚‰ãƒªãƒˆãƒ©ã‚¤ã—ãªãŒã‚‰ upsert ã™ã‚‹"""
    batch_size = len(points_batch)
    
    if DEBUG_MODE:
        print(f"  ğŸ“¤ ãƒãƒƒãƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰é–‹å§‹: {batch_size}ä»¶")
        # ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚µã‚¤ã‚ºã®æ¦‚ç®—
        total_payload_size = sum(len(str(p.payload)) for p in points_batch)
        print(f"  ğŸ“Š æ¨å®šãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚µã‚¤ã‚º: {total_payload_size:,} ãƒã‚¤ãƒˆ")
    
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            start_time = time.time()
            qdrant.upsert(
                collection_name=QDRANT_COLLECTION,
                points=points_batch,
                wait=True,
            )
            elapsed = time.time() - start_time
            if DEBUG_MODE:
                print(f"  âœ… ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {elapsed:.2f}ç§’")
            return
        except UnexpectedResponse as e:
            if getattr(e, "status_code", None) == 502 and attempt < MAX_RETRIES:
                sleep_sec = 2 * attempt
                print(
                    f"  âš ï¸ 502 Bad Gateway "
                    f"(attempt {attempt}/{MAX_RETRIES}) -> {sleep_sec}ç§’å¾…æ©Ÿ"
                )
                time.sleep(sleep_sec)
                continue
            raise
        except Exception as e:
            error_str = str(e).lower()
            if any(keyword in error_str for keyword in ["timeout", "timed out", "connection"]) and attempt < MAX_RETRIES:
                sleep_sec = 5 * attempt  # ã‚ˆã‚Šé•·ã„å¾…æ©Ÿæ™‚é–“
                print(
                    f"  âš ï¸ æ¥ç¶š/ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ "
                    f"(attempt {attempt}/{MAX_RETRIES}) -> {sleep_sec}ç§’å¾…æ©Ÿ"
                )
                print(f"     ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)[:100]}...")
                time.sleep(sleep_sec)
                continue
            print(f"âŒ upsert ä¸­ã«å›å¾©ä¸èƒ½ã‚¨ãƒ©ãƒ¼: {e}")
            raise


def migrate():
    validate_env()

    index = init_pinecone()
    qdrant = init_qdrant()

    stats = index.describe_index_stats()
    total_vectors = stats.get("total_vector_count")
    metric = stats.get("metric", "unknown")
    dim = stats.get("dimension")
    print(f"Pinecone index stats: total={total_vectors}, dim={dim}, metric={metric}")

    if dim != VECTOR_DIM:
        print(f"è­¦å‘Š: Pinecone ã®æ¬¡å…ƒæ•° {dim} ã¨ Qdrant ã®è¨­å®š {VECTOR_DIM} ãŒä¸€è‡´ã—ã¦ã„ã¾ã›ã‚“ã€‚")

    print("\nğŸ”„ Pinecone ã‹ã‚‰ Qdrant ã¸ã®ç§»è¡Œã‚’é–‹å§‹ã—ã¾ã™...")
    print("ğŸ“ Payloadæ§‹é€ ã‚’ãƒ•ãƒ©ãƒƒãƒˆåŒ–ã—ãªãŒã‚‰ç§»è¡Œã—ã¾ã™\n")

    migrated_count = 0
    batch_no = 0

    try:
        id_generator = index.list(namespace=PINECONE_NAMESPACE)
    except Exception as e:
        print("index.list() ã«å¤±æ•—ã—ã¾ã—ãŸã€‚serverless ã§ã¯ãªã„ã‹ã€å¤ã„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        print("ãã®å ´åˆã¯ã€åˆ¥é€” ID ãƒªã‚¹ãƒˆã‚’ã©ã“ã‹ã«ä¿å­˜ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        raise

    for id_batch in id_generator:
        batch_no += 1
        if not id_batch:
            continue

        fetch_res = index.fetch(ids=id_batch, namespace=PINECONE_NAMESPACE)

        if isinstance(fetch_res, dict):
            vectors_dict = fetch_res.get("vectors", {})
        else:
            vectors_dict = getattr(fetch_res, "vectors", {})

        points = []
        for vid, record in vectors_dict.items():
            if isinstance(record, dict):
                values = record.get("values", [])
                metadata = record.get("metadata", {})
            else:
                values = getattr(record, "values", [])
                metadata = getattr(record, "metadata", {})

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆãƒ•ãƒ©ãƒƒãƒˆåŒ–ã¯ä¸è¦ï¼‰
            # original_id ã ã‘è¿½åŠ 
            flattened_payload = metadata.copy()
            flattened_payload["original_id"] = vid

            qdrant_id = to_uuid_from_pinecone_id(vid)

            points.append(
                PointStruct(
                    id=qdrant_id,
                    vector=values,
                    payload=flattened_payload,
                )
            )

        if not points:
            continue

        # Qdrant ç”¨ã«ã•ã‚‰ã«ç´°ã‹ã„ãƒãƒƒãƒã«åˆ†å‰²ã—ã¦ upsert
        print(f"\nğŸ“¦ Batch {batch_no}: {len(points)} ä»¶ã‚’ {MAX_QDRANT_BATCH} ä»¶ãšã¤åˆ†å‰²ã—ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
        
        for i in range(0, len(points), MAX_QDRANT_BATCH):
            sub_points = points[i:i + MAX_QDRANT_BATCH]
            sub_batch_no = (i // MAX_QDRANT_BATCH) + 1
            total_sub_batches = (len(points) + MAX_QDRANT_BATCH - 1) // MAX_QDRANT_BATCH
            
            print(f"  ğŸ“¤ ã‚µãƒ–ãƒãƒƒãƒ {sub_batch_no}/{total_sub_batches}")
            safe_upsert(qdrant, sub_points)
            migrated_count += len(sub_points)
            
            # å„ãƒãƒƒãƒé–“ã«å¾…æ©Ÿæ™‚é–“ã‚’è¿½åŠ ï¼ˆã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ï¼‰
            time.sleep(1.0)

        print(f"âœ… Batch {batch_no} å®Œäº† (ç´¯è¨ˆ {migrated_count}/{total_vectors})")

    print(f"\nâœ… ç§»è¡Œå®Œäº†: åˆè¨ˆ {migrated_count} ãƒ™ã‚¯ãƒˆãƒ«ã‚’ Qdrant ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸã€‚")
    print("\nğŸ“Š ç§»è¡Œå¾Œã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
    print("python check_vector_ids.py")


if __name__ == "__main__":
    migrate()